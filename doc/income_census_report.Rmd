---
title: "Predicting Income levels of an individual"
author: "Aishwarya Gopal, Fei Chang, Yanhua Chen</br>"
date: `r Sys.Date()`
always_allow_html: true
output: 
  html_document:
    toc: true
bibliography: 
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(kableExtra)
library(tidyverse)
# library(caret)
```

```{r load model results}

```

# Summary (To include summary of results after analysis)

Here we attempt to build a classification model using the Logistic Regression algorithm which uses a set of features like age, workclass, education etc to classify the income levels of an indivduals into one of the two categories: >\$50k/year or <=\$50k/year. 

# Introduction

“A large income is the best recipe for happiness I ever heard of” quotes the famous English novelist Jane Austen. While it might not be the only recipe, income dictates the standard of living and economic status of an individual. This data set comprises of numbers from many countries around the world but, about 90% of the data has been collected from the USA. So, we are under the assumption that the median wage required to lead a life in the USA(at the time this data was collected) i.e. $50k per year, was chosen as a threshold for classification. The observations in this data set are classified according to income levels into two categories(>\$50k/year or <=\$50k/year).

Taking into account, the importance and impact of income levels in determining a nation's growth, this study aims to present meaningful insights regarding the same.

# Methods

## Data
The data set used in this project is of income census created by Ronny Kohavi and Barry Becker. It was sourced from the UCI Machine Learning Repository [@Dua2019] and can be found [here](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/), specifically [this file](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data). The data contains information such as age, workclass, education etc. The target variable is income and it is divided into two categories (<=50K and >50K). The ultimate aim is to train a classifier to predict the income class.

## Analysis (TO DO)
The k-nearest neighbors (k-nn) algorithm was used to build a classification model to predict whether a tumour mass was benign or malignant (found in the class column of the data set). All variables included in the original data set, with the exception of the standard error of fractal dimension, smoothness, symmetry and texture were used to fit the model. The hyperparameter $K$ was chosen using 30-fold cross validation with Cohen's Kappa as the classification metric. The R and Python programming languages [@R; @Python] and the following R and Python packages were used to perform the analysis: caret [@caret], docopt [@docopt], feather [@featherr], knitr [@knitr], tidyverse [@tidyverse], docopt [@docoptpython], os [@Python], feather [@featherpy] Pandas [@mckinney-proc-scipy-2010]. The code used to perform the analysis and create this report can be found here: https://github.com/ttimbers/breast_cancer_predictor.

# Results & Discussion

To look at the realationship between some of the predictors and the income class, we plotted the graphs of a few predictors according to the class distribution. In the first plot, we aim to visualise the age distribution for different income levels. From the plot, we can infer that, adults below 30 years earn <=50k a year while those above 43 years earn >50k a year i.e. experience surely plays a role in income levels.

```{r predictor-distributions, echo=FALSE, fig.cap="Figure 1. Comparison of the empirical distributions of training data predictors between benign and malignant tumour masses.", out.width = '100%'}
knitr::include_graphics("../results/predictor_distributions_across_class.png")
```

The relationship between education level and income class is the one that we seek to explore next.

```{r predictor-distributions, echo=FALSE, fig.cap="Figure 1. Comparison of the empirical distributions of training data predictors between benign and malignant tumour masses.", out.width = '100%'}
knitr::include_graphics("../results/predictor_distributions_across_class.png")
```

We chose to use a simple classification model using the k-nearest neighbours algorithm. To find the model that best predicted whether a tumour was benign or malignant, we performed 30-fold cross validation using Cohen's Kappa as our metric of model prediction performance to select K (number of nearest neighbours). We observed that the optimal K was `r model$bestTune$k`.

```{r choosing-k, echo=FALSE, fig.cap="Figure 2. Results from 30-fold cross validation to choose K. Cohen's Kappa was used as the classification metric as K was varied.", out.width = '60%'}
knitr::include_graphics("../results/kappa_vs_k.png")
```

Our prediction model performed quite well on test data, with a final Cohen's Kappa score of `r round(model_quality$overall[2], 1)` and an overall accuracy calculated to be `r round(model_quality$overall[1], 2)`. Other indicators that our model performed well come from the confusion matrix, where it only made `r model_quality$table[2, 1] + model_quality$table[1, 2]` mistakes. However all `r model_quality$table[2, 1] + model_quality$table[1, 2]` mistakes were predicting a malignant tumour as benign, given the implications this has for patients health, this model is not good enough to yet implement in the clinic.


```{r confusion-matrix, echo=FALSE}
kable(model_quality$table, caption = "Table 1. Confusion matrix of model performance on test data.") %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c(" ", "Reference" = 2)) %>% 
  pack_rows("Predicted", 1, 2)
```

To further improve this model in future with hopes of arriving one that could be used in the clinic, there are several things we can suggest. First, we could look closely at the 4 misclassified observations and compare them to several observations that were classified correctly (from both classes). The goal of this would be to see which feature(s) may be driving the misclassification and explore whether any feature engineering could be used to help the model better predict on observations that it currently is making mistakes on. Additionally, we would try seeing whether we can get improved predictions using other classifiers. One classifier we might try is random forest forest because it automatically allows for feature interaction, where k-nn does not. Finally, we also might improve the usability of the model in the clinic if we output and report the probability estimates for predictions. If we cannot prevent misclassifications through the approaches suggested above, at least reporting a probability estimates for predictions would allow the clinician to know how confident the model was in its prediction. Thus the clinician may then have the ability to perform additional diagnostic assays if the probability estimates for prediction of a given tumour class is not very high.

# References

