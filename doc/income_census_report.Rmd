---
title: "Predicting Income levels of an individual"
author: "Aishwarya Gopal, Fei Chang, Yanhua Chen"
date: "2020/11/29"
always_allow_html: true
output:    
   html_document:
     toc: true
bibliography: income_census_refs.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
library(knitr)
library(kableExtra)
library(tidyverse)
```

```{r load eda figures, include=FALSE}
box_plots_numeric <- "../results/box_plots_numeric.png"
correlation_heatmap <- "../results/correlation_heatmap.png"
```

```{r load model results, include=FALSE}
cross_validate_scores <- read.csv("../results/cross_validate_scores.csv")
confusion_matrix <- read.csv("../results/confusion_matrix.csv")%>%
  column_to_rownames(., var = "X")
colnames(confusion_matrix) <- c("<50k", ">=50k")
rownames(confusion_matrix) <- c("<50k", ">=50k")
classification_report <- read.csv("../results/classification_report.csv")
classification_report$X[1] = c("<50k")
classification_report$X[2] = c(">=50k")
feature_importance <- read.csv("../results/feature_importance.csv")%>%
  column_to_rownames(., var = "X")

```

# Summary

Here we attempt to build a classification model using the Logistic Regression algorithm which uses a set of features like age, workclass, education etc to classify the income levels of an indivdual into one of the two categories: \>\$50k/year or \<=\$50k/year. The target class \>=50k was encoded as 1 and the other class as 0. Our final Logistic Regression model performed well on the test data set. We obtained an f1 score of `r round(classification_report$f1.score[2],2)` and an overall accuracy calculated to be `r round(classification_report$precision[3],2)`. It correctly predicted the income class of `r confusion_matrix[1, 1] + confusion_matrix[2, 2]` individuals. However it incorrectly predicted `r confusion_matrix[2, 1] + confusion_matrix[1, 2]` examples.

# Introduction

"A large income is the best recipe for happiness I ever heard of" quotes the famous English novelist Jane Austen. While it might not be the only recipe, income dictates the standard of living and economic status of an individual. So, we decided to study the income distribution of people with different education levels, years of experience etc. The observations in this data set are classified according to income levels, into two categories(\>\$50k/year or \<=\$50k/year). This data set comprises of numbers from many countries around the world but, about 90% of the data has been collected from the USA. So, we are under the assumption that, the median wage required to lead a life in the USA (at the time this data was collected) i.e. \$50k per year, was chosen as a threshold for classification.

Taking into account, the importance and impact of income levels in determining a nation's growth, this study aims to present meaningful insights regarding the same.

# Methods

## Data

The data set used in this project is of income census created by Ronny Kohavi and Barry Becker. It was sourced from the UCI Machine Learning Repository and can be found [here](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/), specifically [this file](https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data). The data contains information such as age, workclass, education etc. The target variable is income and it is divided into two categories (\<=50K and \>50K). The ultimate aim is to train a classifier to predict the income class.

## Analysis

The logistic regression algorithm was used to build a classification model to predict whether an individual earns \>\$50k/year or \<=\$50k/year. All the variables in original data set except for education column was used. The education.num column is just a numerical representation of the education level of an individual. f1 score was chosen as the desired metric and a 10 fold cross-validation was performed on the train set. The R and Python programming languages [@R; @Python] and the following R and Python packages were used to perform the analysis: docopt [@docopt], knitr [@knitr], tidyverse [@tidyverse], docopt [@docoptpython], os [@Python], Pandas [@mckinney-proc-scipy-2010]. The code used to perform the analysis and create this report can be found here: <https://github.com/UBC-MDS/DSCI_522_Group_18>.

# Results & Discussion

### Explanatory Data Analysis

To look at the realationship between some of the predictors and the income class, we plotted the graphs of a few predictors according to the class distribution.

```{r Boxplots of Numeric variables, echo=FALSE, fig.cap="Figure 1. Boxplots of numeric variables categorized by target variable", out.width = '100%'}

knitr::include_graphics(box_plots_numeric)
```

The box plots of all scaled numeric features categorized by the target variable is presented above. The target 0 is \<50k and the target 1 is \>=50k.

From the above plot, it can be inferred that, in general as age increases, i.e. experience level increases, there tends to be higher income levels.

Individuals with income \>50k have longer average working hours per week than individuals with \<50k. But there are some individuals who have income \<50k, but have higher work hours.

Another important inference is that people with higher education levels earn more on an average than people with lower education levels.

Other numerical variables such as capital\_loss and capital\_gain tend to have very low median values but have a significantly high number of outliers.

The next area of concern is collinearity. When two numeric input variables are highly correlated, it is almost impossible to change the value of one input variable without changing the other. Hence, the coefficients become very sensitive to small changes in the model and the coefficient estimates tend to swing wildly. To address this, we plotted a correlation heatmap.

From the below correlation heatmap, we can observe that none of the numeric variables seem to be highly correlated. Hence, we decided to retain all the features except education (education and education.num present the same information) for training the model.

```{r fig.height=4, fig.width=4}
knitr::include_graphics(correlation_heatmap)
```

### Model Selection

We chose to build a simple classification model. To find the model that best predicted whether an individual earns \>50k or \<=50k, we performed 10-fold cross validation using the Logistic regression algorithm and Random Forest Classification. We observed that the Random Forest Classification generates a higher training accuracy and f1 score, however, its advantage in cross-validation scores is not obvious. Meanwhile, the gap between train and cross-validation score is very large in Random Forest Classification, which indicates the model is overfitted. At this point, we decide to use Logistic Regression algorithm to build the prediction model.

```{r present cross validation score, echo=FALSE}
kable(cross_validate_scores %>% mutate_if(is.numeric, round, 3), caption = "Table 1. Cross validate scores of model performance on train data.") %>%
  kable_styling(full_width = FALSE)
```

### Feature Importance

Looking through the feature importance of our model, we found some interesting information:

It seems that married people usually have higher probability to gain more than 50k per year, especially for females (relationship\_Wife), while people who are never married have higher probability to gain less than 50k.

```{r present feature importance, echo=FALSE}
kable(feature_importance %>% mutate_if(is.numeric, round, 3), caption = "Table 2. feature importance of final model") %>%
  kable_styling(full_width = FALSE)
```

### Results

Our prediction model performed quite well on test data, the confusion matrix below indicates it only made `r confusion_matrix[2, 1] + confusion_matrix[1, 2]` mistakes, so the test accuracy is `r round((confusion_matrix[1,1] + confusion_matrix[2,2])/sum(confusion_matrix),3)`. It predicted `r confusion_matrix[2, 1]` examples as belonging to "\>=50K" group while they actually belong to the "\<50K" group. These are termed as False Positives(FP). The model predicted `r confusion_matrix[1, 2]` as "\<50K" group while the actual prediction is "\>=50K". These are termed as False Negatives(FN). The examples correctly predicted as belonging to "\<50K" group are termed as True Negatives(TN) and the examples correctly predicted as belonging to "\>=50K" group are termed as True Positives(TP). However, most of the mistake are from the "\>=50K" group.

```{r confusion-matrix, echo=FALSE}
kable(confusion_matrix, caption = "Table 3. Confusion matrix of model performance on test data.") %>%
  kable_styling(full_width = FALSE) %>%
  add_header_above(c(" ", "Reference" = 2)) %>% 
  pack_rows("Predicted", 1, 2)
```

This problem is also reflected by the classification report, that the f1.score of "\>=50k" group is much lower than "\<50k" group. Precision is calculated as TP/(TP+FP) while Recall is calculated as (TP/TP+FN). f1 score is the harmonic mean of Precision and Recall. This model is not good enough to yet predict the income status of rich people.

```{r}
kable(classification_report[-3,] %>% mutate_if(is.numeric, round, 3), caption = "Table 4. Classification report of model performance on test data.")%>%
  kable_styling(full_width = FALSE)
```

### Further Discussion

To further improve this model in future, we have attempted tune hyperparameters and also applied feature selection on it. However, both approaches didn't help to improve the model improvements. There are several things we can suggest which beyond our capability . First, exploring some method about feature engineering which might be helpful to improve the model performance. Second, because the misclassification is concentrated in \>50k group, having more data from that group will improve the prediction accuracy.

# References
